{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20552a8-77d7-4e34-abfd-5617389700f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 1)\n",
    "KNN, or k-Nearest Neighbors, is a supervised machine learning algorithm used for both classification and regression tasks. It works by finding the 'k' nearest data points in the feature space to a given input and then making predictions based on the majority class (for classification) or averaging the values (for regression) of these neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0adaf7-cdbe-4e2d-8a55-78c9c6487721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 2)\n",
    "The choice of the value of K in KNN is crucial for the model's performance. A smaller K value makes the model sensitive to noise, while a larger K value may make the boundaries between classes less distinct. Common methods to choose K include cross-validation, grid search, or using rules of thumb based on the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e9c27-f3d9-4c2a-ab5d-4dfadadc6987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3)\n",
    "KNN Classifier: Predicts the class of a new data point based on the majority class of its k-nearest neighbors.\n",
    "KNN Regressor: Predicts a continuous value for a new data point based on the average of the values of its k-nearest neighbors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed22a5-6eab-4e99-8b51-3eaed2ae6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4)\n",
    "Common metrics for evaluating KNN performance include accuracy, precision, recall, F1 score for classification, and mean squared error, R-squared for regression tasks. Cross-validation can also be used to assess generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6e85e1-e498-4dbc-a968-9d4b01899621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 5)\n",
    "The curse of dimensionality refers to the increased sparsity of data as the number of features (dimensions) increases. In KNN, this can lead to increased distances between data points, making it difficult to identify meaningful nearest neighbors and potentially degrading the algorithm's performance. Feature selection or dimensionality reduction techniques can help mitigate this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e4636b-cb97-443d-8be4-7bc4dd003b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6)\n",
    "Imputation techniques, such as replacing missing values with the mean or median, can be used in KNN. Another approach involves treating missing values as a separate category during distance computation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3d6e37-89b7-474f-b30d-48f88860ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7)\n",
    "KNN Classifier is suitable for problems with discrete classes (e.g., spam detection).\n",
    "KNN Regressor is appropriate for problems where the output is a continuous value (e.g., predicting house prices).\n",
    "The choice depends on the nature of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14da6cce-372a-458e-b0e0-f1e84ec7afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 8)\n",
    "Strengths:\n",
    "\n",
    "Simple and easy to understand.\n",
    "Effective for small to moderately sized datasets with fewer dimensions.\n",
    "Weaknesses:\n",
    "\n",
    "Computationally expensive for large datasets.\n",
    "Sensitive to irrelevant features.\n",
    "Performance can be affected by the choice of K.\n",
    "Addressing these issues may involve dimensionality reduction, feature scaling, or using approximation methods for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351743b2-0a99-4609-a5ef-4fed38695bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 9)\n",
    "Euclidean distance: Represents the straight-line distance between two points in space.\n",
    "Manhattan distance: Represents the sum of the absolute differences between corresponding coordinates of two points in space. It is also known as the L1 norm.\n",
    "The choice between them depends on the nature of the data and the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e81189-1838-4279-947a-5e2ede7d2c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 10)\n",
    "Feature scaling is crucial in KNN because the algorithm relies on the distance between data points. If features have different scales, the contribution of one feature to the distance may dominate others. Common scaling methods include Min-Max scaling or Z-score normalization, ensuring that all features contribute equally to the distance metric."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
